library(tidyverse)
library(dplyr)
library(tibble)
library(ggplot2)
data()
data("population")
force(population)
head(population)
nrow(population)
ncol(population)
population_data<-as_tibble(population)
population_data
filter(population, population>20000000)
filter(population, country=="India")
filter(population, country=="India", year>2000)
select(population_data,country, population)
select(population_data, c(country, population))
newpopdata<-mutate(population_data,npop=population/1000)
newpopdata
arrange(population_data,year)
arrange(population_data,desc(population))
population_data %>%
filter(country=="Bangladesh")
population_data %>%
filter(country=="Bangladesh")%>%
filter(year>2005)
country_data=filter(population_data, country=="India")
countery_data=arrange(country_data,year)
country_data
ggplot(country_data, mapping=aes(x=year,y=population))+geom_point()
ggplot(country_data, mapping=aes(x=year,y=population))+geom_point(alpha=0.5)
ggplot(country_data, mapping=aes(x=year,y=population))+geom_jitter(width=10,height=10)
ggplot(country_data, mapping=aes(x=year,y=population))+geom_line()
ggplot(country_data)+geom_text(mapping=aes(x=year,y=population,label=year))
ggplot(country_data,mapping=aes(x=population))+geom_histogram(bins=5)
ggplot(country_data,mapping=aes(x=population))+geom_histogram(bins=5, color="turquoise")
ggplot(country_data,mapping=aes(x=population))+geom_histogram(bins=5, color="turquoise",fill="maroon")
ggplot(country_data,mapping=aes(x=population))+geom_boxplot()
diffcountry_data=filter(population_data,country==c("India","Bangladesh","Pakistan","Afghanistan"))
ggplot(data=diffcountry_data, mapping=aes(x=factor(country),y=population))+geom_boxplot()
ggplot(data=diffcountry_data,mapping=aes(x=country,y=population))+geom_col()
ggplot(data=diffcountry_data, mapping=aes(x=population))+geom_histogram(bins=4,color="steelblue",fill="turquoise2")+facet_wrap(~country,nrow=3)
knitr::opts_chunk$set(echo = TRUE)
ggplot(mpg, aes(x = displ, y = hwy, color = class)) + geom_point() +
labs(title = "Fuel Efficiency by Engine Power",
subtitle = "Fuel economy data from 1999 and 2008 for 38 popular models of cars",
x = "Engine power (litres displacement)",
y = "Fuel Efficiency (miles per gallon)",
color = "Car Type") + theme_classic()
ggsave('Delhi.png', width = 8, height = 6)
knitr::opts_chunk$set(echo = TRUE)
ggplot(mpg, aes(x = displ, y = hwy)) +
geom_point() +
facet_grid(year ~ cyl)
# Loading the packages
library(tidyverse)
library(dplyr)
library(tibble)
library(ggplot2)
ggplot(mpg, aes(x = displ, y = hwy)) +
geom_point() +
facet_grid(year ~ cyl)
data(mpg)
?mpg
force(mpg)
View(mpg)
#Change the path according to your PC
path = "/Users/lenovo1/Desktop/mtech/courses/stats/Datasets/data/"
fileN ="aflsmall.Rdata"
file_path = paste(path,fileN, sep = "")
load(file_path)
#Change the path according to your PC
path = "/Users/lenovo1/Desktop/mtech/courses/stats/Datasets/data/"
fileN ="aflsmall.Rdata"
file_path = paste(path,fileN, sep = "")
load(file_path)
#Change the path according to your PC
path = "/Users/lenovo1/Desktop/mtech/courses/stats/Datasets/data/"
fileN ="aflsmall.Rdata"
file_path = paste(path,fileN, sep = "")
load(file_path)
#Change the path according to your PC
path = "/Users/lenovo1/Desktop/mtech/courses/stats/Datasets/data/"
fileN ="aflsmall.Rdata"
file_path = paste(path,fileN, sep = "")
load(file_path)
#Initial packages
install.packages("lsr")
setwd("C:/Users/User/Documents/GitHub/BSE658/Module 3")
#Change the path according to your PC
path = "/Users/lenovo1/Desktop/mtech/courses/stats/Datasets/data/"
fileN ="aflsmall.Rdata"
file_path = paste(path,fileN, sep = "")
load(file_path)
getwd()
setwd("C:/Users/User/Documents/GitHub/BSE658/Module 3/Notebooks")
#Change the path according to your PC
path = "/Users/lenovo1/Desktop/mtech/courses/stats/Datasets/data/"
fileN ="aflsmall.Rdata"
file_path = paste(path,fileN, sep = "")
load(file_path)
setwd("C:/Users/User/Documents/GitHub/BSE658/Module 3/Notebooks")
setwd()
getwd()
load("~/GitHub/BSE658/Module 3/Notebooks/aflsmall.Rdata")
#Change the path according to your PC
path = "/Users/lenovo1/Desktop/mtech/courses/stats/Datasets/data/"
fileN ="aflsmall.Rdata"
file_path = paste(path,fileN, sep = "")
load(file_path)
#Change the path according to your PC
#path = "/Users/lenovo1/Desktop/mtech/courses/stats/Datasets/data/"
path="/GitHub/BSE658/Module 3/Notebooks/"
fileN ="aflsmall.Rdata"
file_path = paste(path,fileN, sep = "")
load(file_path)
#Change the path according to your PC
#path = "/Users/lenovo1/Desktop/mtech/courses/stats/Datasets/data/"
path="/GitHub/BSE658/Module 3/Notebooks/"
fileN ="aflsmall.Rdata"
#file_path = paste(path,fileN, sep = "")
load(file_path)
#Change the path according to your PC
#path = "/Users/lenovo1/Desktop/mtech/courses/stats/Datasets/data/"
#file_path = paste(path,fileN, sep = "")
#path="/GitHub/BSE658/Module 3/Notebooks/"
#fileN ="aflsmall.Rdata"
load(file_path)
#Change the path according to your PC
#path = "/Users/lenovo1/Desktop/mtech/courses/stats/Datasets/data/"
#file_path = paste(path,fileN, sep = "")
#path="/GitHub/BSE658/Module 3/Notebooks/"
#fileN ="aflsmall.Rdata"
#load(file_path)
#library(lsr)
#who()
load(aflsmall.Rdata)
#Change the path according to your PC
#path = "/Users/lenovo1/Desktop/mtech/courses/stats/Datasets/data/"
#file_path = paste(path,fileN, sep = "")
#path="/GitHub/BSE658/Module 3/Notebooks/"
#fileN ="aflsmall.Rdata"
#load(file_path)
#library(lsr)
#who()
load("aflsmall.Rdata")
print (afl.margins)
hist (afl.margins)
A<-C(35,40,45,50,55)
A<-C(35,40,45,50,55)
a<-C(35,40,45,50,55)
a<-C(35,40,45,50,55)
a <-C(35,40,45,50,55)
a <-c(35,40,45,50,55)
sum(a)/length(a)
mean(a)
a <-c(35,40,45,50,55)
sum(a)/length(a)
mean(a)
median(a)
a <-c(35,40,45,50,55)
sum(a)/length(a)
mean(a)
median(a)
min(a)
max(a)
range(a)
IQR(a)
dataset <- c(-15,2,3,4,5,6,7,8,9,12)
mean(x = dataset, trim = .1)
#Try calculating 5% trimmed mean for above dataset
#Find range of afl.margins here
#afl.mode =
#afl.mode
#Use the functions quantile(x = afl.margins, prob = 0.2) for 20% quantile and IQR()
a <-c(35,40,45,50,55)
sum(a)/length(a)
mean(a)
median(a)
min(a)
max(a)
range(a)
IQR(a)
var(a)
a <-c(35,40,45,50,55)
sum(a)/length(a)
mean(a)
median(a)
min(a)
max(a)
range(a)
IQR(a)
var(a)
sd(a)
#setwd("/Users/lenovo1/Desktop/mtech/courses/stats/Datasets/data/")
#Let's load some data
load("parenthood.Rdata")
#str(parenthood)
#who(TRUE)
str(parenthood)
library(psych)
install.packages("lsr")
library(psych)
library(psych)
library(psych)
#Try describe() for the above data frame
list.files()
View(parenthood)
#Try describe() for the above data frame
describe(baby.sleep)
attach(parenthood)
#Try describe() for the above data frame
describe(baby.sleep)
#Let's also take a graphical look at the data
hist(parenthood$dan.sleep)
#Try plotting for the other 2 variables
install.packages("car")
install.packages("Rcpp")
library(car)
scatterplot( dan.grump ~ dan.sleep, data = parenthood, regLine = FALSE, smooth = FALSE)
scatterplot
#Plot a scatter plot for baby.sleep and dan.grump variables
scatterplot( dan.grump ~ baby.sleep, data = parenthood, regLine = FALSE, smooth = FALSE)
scatterplot
#Plot baby sleep and dan sleep here
scatterplot( baby.sleep ~ dan.sleep, data = parenthood, regLine = FALSE, smooth = FALSE)
scatterplot
cor(x = parenthood$dan.sleep, y = parenthood$dan.grump)
#Try giving the entire dataframe 'parenthood' as input in cor()
load("~/GitHub/BSE658/Module 3/Notebooks/anscombesquartet.Rdata")
load( "anscombesquartet.Rdata" )
cor( X1, Y1 )
cor( X2, Y2 )
cor (X3, Y3)
cor (X4, Y4)
scatterplot()
scatterplot(X1 ~ Y1, data =anscombesquartet.Rdata , regLine = FALSE, smooth = FALSE)
scatterplot(X1 ~ Y1, data =anscombesquartet.Rdata , regLine = FALSE, smooth = FALSE)
load("~/GitHub/BSE658/Module 3/Notebooks/anscombesquartet.Rdata")
head(anscombesquartet.Rdata)
print(anscombesquartet.Rdata)
#setwd("/Users/lenovo1/Desktop/mtech/courses/stats/Datasets/data/")
load( "effort.Rdata" )
effort
cor( effort$hours, effort$grade )
#Try it out yourself
#Define a vector with Grumpiness scores of you and your friends and find the z score for your self
X =  35
z = (X - mean(X)) / sd(X)
#Try it out yourself
#Define a vector with Grumpiness scores of you and your friends and find the z score for your self
X =
z = (X - mean(X)) / sd(X)
head(parenthood,10)
describe(parenthood)
#Try describe() for the above data frame
#Try describe() for the above data frame
describe(parenthood)
cor( x = parenthood )
knitr::kable(
rbind(
c("-1.0 to -0.9" ,"Very strong", "Negative"),
c("-0.9 to -0.7", "Strong", "Negative") ,
c("-0.7 to -0.4", "Moderate", "Negative") ,
c("-0.4 to -0.2", "Weak", "Negative"),
c("-0.2 to 0","Negligible", "Negative") ,
c("0 to 0.2","Negligible", "Positive"),
c("0.2 to 0.4", "Weak", "Positive"),
c("0.4 to 0.7", "Moderate", "Positive"),
c("0.7 to 0.9", "Strong", "Positive"),
c("0.9 to 1.0", "Very strong", "Positive")), col.names=c("Correlation", "Strength", "Direction"),
booktabs = TRUE)
scatterplot(X1 ~ Y1, data =anscombesquartet , regLine = FALSE, smooth = FALSE)
scatterplot(X ~ Y, data =anscombesquartet , regLine = FALSE, smooth = FALSE)
View(effort)
>effort
scatterplot(effort$hours, effort$grade, regLine = TRUE, smooth = FALSE)
scatterplot(anscombesquartet$X1 ~ anscombesquartet$Y1, regLine = FALSE, smooth = FALSE)
hours.rank <- rank( effort$hours )   # rank students by hours worked
grade.rank <- rank( effort$grade )   # rank students by grade received
#Now try cor() function for these
cor( hours.rank, grade.rank )
#Execute this and compare with the correlation coefficient we got above
cor( effort$hours, effort$grade, method = "spearman")
load( "parenthood2.Rdata" )
print( parenthood2 )
describe( parenthood2 )
#Check how many missing values are there for each variable - compare the values in 'n' with the number of days.
cor(parenthood2)
cor(parenthood2, use = "complete.obs")
cor(parenthood2, use = "pairwise.complete.obs")
library(ggplot2)
# Basic scatter plot
ggplot(parenthood, aes(x = dan.sleep, y = dan.grump)) + geom_point() + geom_point() + geom_smooth()
library(ggplot2)
# Basic scatter plot
ggplot(parenthood, aes(x = dan.sleep, y = dan.grump)) + geom_point() + geom_point() + geom_smooth()
#Plot a scatter plot for baby.sleep and dan.grump variables
ggplot(parenthood, aes(x = baby.sleep, y = dan.grump)) + geom_point()
#Plot baby sleep and dan sleep here
scatterplot( baby.sleep ~ dan.sleep, data = parenthood, regLine = FALSE, smooth = FALSE)
scatterplot
cor(x = parenthood$dan.sleep, y = parenthood$dan.grump)
#Try giving the entire dataframe 'parenthood' as input in cor()
#correlate all pairs of variables in "parenthood":
cor( x = parenthood )
install.packages("ggcorrplot")
library(ggcorrplot)
corr <- round(cor(parenthood), 1)
corr
p.mat <- cor_pmat(parenthood)
p.mat
ggcorrplot(corr)
ggcorrplot(corr, method = "circle")
ggcorrplot(corr, hc.order = TRUE, type = "lower",
lab = TRUE)
scatterplot(x = X1, y = Y1,regLine = FALSE, smooth = FALSE)
scatterplot(x = X2, y = Y2,regLine = FALSE, smooth = FALSE)
scatterplot(x = X3, y = Y3,regLine = FALSE, smooth = FALSE)
scatterplot(x = X4, y = Y4,regLine = FALSE, smooth = FALSE)
#setwd("/Users/lenovo1/Desktop/mtech/courses/stats/Datasets/data/")
load( "effort.Rdata" )
effort
cor( effort$hours, effort$grade )
scatterplot(effort$hours, effort$grade, regLine = TRUE, smooth = FALSE)
hours.rank <- rank( effort$hours )   # rank students by hours worked
grade.rank <- rank( effort$grade )   # rank students by grade received
#Now try cor() function for these
cor( hours.rank, grade.rank )
#Execute this and compare with the correlation coefficient we got above
cor( effort$hours, effort$grade, method = "spearman")
load( "parenthood2.Rdata" )
print( parenthood2 )
describe( parenthood2 )
#Check how many missing values are there for each variable - compare the values in 'n' with the number of days.
cor(parenthood2)
cor(parenthood2, use = "complete.obs")
cor(parenthood2, use = "pairwise.complete.obs")
load("work.Rdata")
head(work)
cor(work)
View(work)
correlate(work)
partial <- c(10, 20, NA, 30)
median(partial, na.rm = TRUE)
sleep <- c(NA, 9,10)
grump <- c(70, NA, 30)
plot(cars)
install.packages("ggcorrplot")
install.packages("ggcorrplot")
install.packages("ggcorrplot")
library(ggcorrplot)
# Compute a correlation matrix
data(mtcars)
corr <- round(cor(mtcars), 1)
head(corr[, 1:6])
# Compute a matrix of correlation p-values
p.mat <- cor_pmat(mtcars)
head(p.mat[, 1:4]
library(ggcorrplot)
# Compute a matrix of correlation p-values
p.mat <- cor_pmat(mtcars)
head(p.mat[, 1:4]
# Visualize the correlation matrix
# --------------------------------
# method = "square" (default)
ggcorrplot(corr)
# method = "circle"
ggcorrplot(corr, method = "circle")
# method = "circle"
ggcorrplot(corr, method = "circle")
# Reordering the correlation matrix
# --------------------------------
# using hierarchical clustering
ggcorrplot(corr, hc.order = TRUE, outline.col = "white")
# Types of correlogram layout
# --------------------------------
# Get the lower triangle
ggcorrplot(corr, hc.order = TRUE, type = "lower",
outline.col = "white")
# Get the upeper triangle
ggcorrplot(corr, hc.order = TRUE, type = "upper",
outline.col = "white")
# Change colors and theme
# --------------------------------
# Argument colors
ggcorrplot(corr, hc.order = TRUE, type = "lower",
outline.col = "white",
ggtheme = ggplot2::theme_gray,
colors = c("#6D9EC1", "white", "#E46726"))
# Add correlation coefficients
# --------------------------------
# argument lab = TRUE
ggcorrplot(corr, hc.order = TRUE, type = "lower",
lab = TRUE)
# Add correlation significance level
# --------------------------------
# Argument p.mat
# Barring the no significant coefficient
ggcorrplot(corr, hc.order = TRUE,
type = "lower", p.mat = p.mat)
# Leave blank on no significant coefficient
ggcorrplot(corr, p.mat = p.mat, hc.order = TRUE,
type = "lower", insig = "blank")
# Compute a matrix of correlation p-values
p.mat <- cor_pmat(mtcars)
head(p.mat[, 1:4]
# Compute a matrix of correlation p-values
p.mat <- cor_pmat(mtcars)
head( p.mat[, 1:4]
# Compute a matrix of correlation p-values
p.mat <- cor_pmat(mtcars)
head(p.mat[, 1:4])
View(mtcars)
correlate( work, corr.method="spearman" )
setwd("C:/Users/User/Documents/GitHub/BSE658/Module 3")
source("~/GitHub/BSE658/Module 3/Notebooks/Notebook4_mtcars.Rmd")
